{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caf47cf-c7d5-4635-a315-748b02ff2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "sys.path.append(\"./training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11ff1b9-3492-49fb-8144-6dac2a426a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import worker_init_fn, get_pdbs, loader_pdb, build_training_clusters, PDB_dataset, StructureDataset, StructureLoader\n",
    "\n",
    "data_path = \"./pdb_2021aug02_sample\"\n",
    "params = {\n",
    "    \"LIST\"    : f\"{data_path}/list.csv\", \n",
    "    \"VAL\"     : f\"{data_path}/valid_clusters.txt\",\n",
    "    \"TEST\"    : f\"{data_path}/test_clusters.txt\",\n",
    "    \"DIR\"     : f\"{data_path}\",\n",
    "    \"DATCUT\"  : \"2030-Jan-01\",\n",
    "    \"RESCUT\"  : 3.5, #resolution cutoff for PDBs\n",
    "    \"HOMO\"    : 0.70 #min seq.id. to detect homo chains\n",
    "}\n",
    "\n",
    "LOAD_PARAM = {'batch_size': 1,\n",
    "              'shuffle': False,\n",
    "              'pin_memory':False,\n",
    "              'num_workers': 4}\n",
    "\n",
    "train, valid, test = build_training_clusters(params, False)\n",
    "\n",
    "train_set = PDB_dataset(list(train.keys()), loader_pdb, train, params)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, worker_init_fn=worker_init_fn, **LOAD_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23731fd-da05-4343-8477-12217c35b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_dict_train = get_pdbs(train_loader)\n",
    "dataset_train = StructureDataset(pdb_dict_train, truncate=None, max_length=100000)\n",
    "loader_train = StructureLoader(dataset_train, batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573d358-b78f-4028-a175-71a7c605a3b0",
   "metadata": {},
   "source": [
    "### Mess around with architecture here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1587187b-9d95-4e38-ad03-d35892146549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import ProteinFeatures, PositionWiseFeedForward, gather_nodes, cat_neighbors_nodes\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EncLayer(nn.Module):\n",
    "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
    "        super(EncLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_in = num_in\n",
    "        self.scale = scale\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(num_hidden)\n",
    "        self.norm2 = nn.LayerNorm(num_hidden)\n",
    "        self.norm3 = nn.LayerNorm(num_hidden)\n",
    "\n",
    "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.act = torch.nn.GELU()\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "\n",
    "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
    "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
    "        \n",
    "        # Compute node update.\n",
    "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
    "        ## Duplicates the node embeddings up to K (nearest neighbors) for concatenation with edge embeddings.\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
    "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
    "        ## Compute message passing through linear layers in self.num_hidden embedding space.\n",
    "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
    "        \n",
    "        ## mask_V and mask_attend will not be None during training at least.\n",
    "        ## Zeros out the updates to the indices being ignored, before the update is applied to the node embeddings.\n",
    "        if mask_attend is not None:\n",
    "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
    "            \n",
    "        ## Compute the message by summing over the neighbor indices and dividing by a scale factor (should probably be the degree)\n",
    "        dh = torch.sum(h_message, -2) / self.scale\n",
    "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
    "        dh = self.dense(h_V)\n",
    "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
    "        \n",
    "        ## mask_V and mask_attend will not be None during training at least.\n",
    "        ## Zeros out the nodes being ignored, after the update is applied to the node embeddings (removes any layer biases added to the zeroed nodes).\n",
    "        if mask_V is not None:\n",
    "            mask_V = mask_V.unsqueeze(-1)\n",
    "            h_V = mask_V * h_V\n",
    "\n",
    "        # Compute edge update.\n",
    "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
    "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
    "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
    "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
    "        ## Looks like encoder block does not perform a 'dense layer' update for edge embeddings.\n",
    "        return h_V, h_E\n",
    "\n",
    "\n",
    "\n",
    "class DecLayer(nn.Module):\n",
    "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
    "        super(DecLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_in = num_in\n",
    "        self.scale = scale\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(num_hidden)\n",
    "        self.norm2 = nn.LayerNorm(num_hidden)\n",
    "\n",
    "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
    "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
    "        self.act = torch.nn.GELU()\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "\n",
    "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
    "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
    "        # The decoding layer works exactly like the encoding layer, but it does not perform an edge update. See line-by-line explanation from above.\n",
    "\n",
    "        # This block computes the node update.\n",
    "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1) \n",
    "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
    "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
    "        if mask_attend is not None:\n",
    "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
    "        dh = torch.sum(h_message, -2) / self.scale \n",
    "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
    "        dh = self.dense(h_V)\n",
    "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
    "        if mask_V is not None:\n",
    "            mask_V = mask_V.unsqueeze(-1)\n",
    "            h_V = mask_V * h_V\n",
    "            \n",
    "        # Return updated node embeddings.\n",
    "        return h_V\n",
    "\n",
    "class ProteinMPNN(nn.Module):\n",
    "    def __init__(self, num_letters=21, node_features=128, edge_features=128,\n",
    "        hidden_dim=128, num_encoder_layers=3, num_decoder_layers=3,\n",
    "        vocab=21, k_neighbors=32, augment_eps=0.1, dropout=0.1):\n",
    "        super(ProteinMPNN, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.node_features = node_features\n",
    "        self.edge_features = edge_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
    "\n",
    "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
    "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all):\n",
    "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
    "        device=X.device\n",
    "        \n",
    "        # Prepare node and edge embeddings\n",
    "        # Constructs edge features from X.\n",
    "        # Computes virtual Cb atom position and encodes into RBF, adds additional edge features as needed.\n",
    "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
    "        \n",
    "        # Node features are intialized to zeros in the same hidden dimensionality as edges (128 by default)\n",
    "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
    "        # Linear transformation over the edges to move them into the hidden dimensionality\n",
    "        h_E = self.W_e(E)\n",
    "\n",
    "        # Encoder is unmasked self-attention\n",
    "        # Duplicate the mask out to K (nearest neighbors) so that it can be used to mask which nearest neighbors will be used.\n",
    "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
    "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
    "        \n",
    "        # Perform the forward pass of the encoder layers with checkpointing.\n",
    "        # Computes a node and edge update which is used as input to the next layer and builds up the node representation.\n",
    "        for layer in self.encoder_layers:\n",
    "            h_V, h_E = torch.utils.checkpoint.checkpoint(layer, h_V, h_E, E_idx, mask, mask_attend)\n",
    "        \n",
    "\n",
    "        # Concatenate sequence embeddings for autoregressive decoder\n",
    "        # Concatenates linear transformation of sequence (not one-hot encoded for some reason) to edge embeddings in place of node embeddings. \n",
    "        # Moves sequence from [B, N] -> [B, N, (node embedding) 128]\n",
    "        h_S = self.W_s(S)\n",
    "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "        # Build encoder embeddings\n",
    "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
    "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
    "\n",
    "\n",
    "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
    "        decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(torch.randn(chain_M.shape, device=device)))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
    "        mask_size = E_idx.shape[1]\n",
    "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
    "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
    "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
    "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
    "        mask_bw = mask_1D * mask_attend\n",
    "        mask_fw = mask_1D * (1. - mask_attend)\n",
    "\n",
    "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
    "        for layer in self.decoder_layers:\n",
    "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
    "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
    "            h_V = torch.utils.checkpoint.checkpoint(layer, h_V, h_ESV, mask)\n",
    "\n",
    "        logits = self.W_out(h_V)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d427da-4d2e-40c7-9d35-c4bda703c201",
   "metadata": {},
   "source": [
    "### Run the messed-with model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d597816-2008-433d-9745-42ef6bb5983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import featurize\n",
    "\n",
    "model = ProteinMPNN(\n",
    "    node_features=128, \n",
    "    edge_features=128, \n",
    "    hidden_dim=128, \n",
    "    num_encoder_layers=3, \n",
    "    num_decoder_layers=3, \n",
    "    k_neighbors=5, # Set this to 1 for simplicity during analysis.\n",
    "    # k_neighbors=48, \n",
    "    dropout=0.1, \n",
    "    augment_eps=0.2\n",
    ")\n",
    "\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa4af89d-d113-495f-a80b-6736b13cb79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein Lengths:\n",
      "[90, 139, 164, 204, 233, 249, 249, 260, 280, 292, 294, 337, 574, 586] \n",
      "\n",
      "torch.Size([14, 586])\n",
      "tensor([[10, 11,  9,  ...,  0,  0,  0],\n",
      "        [ 5, 13,  8,  ...,  0,  0,  0],\n",
      "        [10, 11,  7,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [15, 15,  5,  ...,  0,  0,  0],\n",
      "        [15, 15,  5,  ...,  0,  0,  0],\n",
      "        [15,  9,  0,  ...,  6,  6, 15]])\n",
      "torch.Size([14, 586, 128])\n",
      "tensor([[[-0.1957, -0.1921,  0.1424,  ...,  0.1462,  0.0110,  0.1728],\n",
      "         [-0.1910, -0.1572,  0.0122,  ...,  0.0282, -0.1432,  0.0211],\n",
      "         [-0.1466,  0.0862,  0.1330,  ...,  0.0394, -0.1964, -0.1265],\n",
      "         ...,\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836]],\n",
      "\n",
      "        [[-0.1215,  0.1197,  0.0687,  ..., -0.0513, -0.0588, -0.0649],\n",
      "         [-0.0141, -0.0974, -0.0692,  ...,  0.1760, -0.0365, -0.0037],\n",
      "         [ 0.0753, -0.0950, -0.1146,  ..., -0.0123, -0.1693, -0.1793],\n",
      "         ...,\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836]],\n",
      "\n",
      "        [[-0.1957, -0.1921,  0.1424,  ...,  0.1462,  0.0110,  0.1728],\n",
      "         [-0.1910, -0.1572,  0.0122,  ...,  0.0282, -0.1432,  0.0211],\n",
      "         [ 0.1275,  0.0230,  0.1950,  ...,  0.1495,  0.0207, -0.0139],\n",
      "         ...,\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001],\n",
      "         [ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001],\n",
      "         [-0.1215,  0.1197,  0.0687,  ..., -0.0513, -0.0588, -0.0649],\n",
      "         ...,\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836]],\n",
      "\n",
      "        [[ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001],\n",
      "         [ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001],\n",
      "         [-0.1215,  0.1197,  0.0687,  ..., -0.0513, -0.0588, -0.0649],\n",
      "         ...,\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836]],\n",
      "\n",
      "        [[ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001],\n",
      "         [-0.1466,  0.0862,  0.1330,  ...,  0.0394, -0.1964, -0.1265],\n",
      "         [-0.0207, -0.1820, -0.0326,  ...,  0.0475,  0.1860,  0.0836],\n",
      "         ...,\n",
      "         [ 0.0154, -0.1285,  0.1506,  ...,  0.1996, -0.1372,  0.1940],\n",
      "         [ 0.0154, -0.1285,  0.1506,  ...,  0.1996, -0.1372,  0.1940],\n",
      "         [ 0.1896,  0.1388, -0.1644,  ...,  0.0916,  0.1780, -0.2001]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m mask_for_loss \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m*\u001b[39m chain_M\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass (is sequence aware!!), this is what we want to replicate for our model.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidue_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_encoding_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/pyrosetta/envs/torch-nightly/lib/python3.8/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36mProteinMPNN.forward\u001b[0;34m(self, X, S, mask, chain_M, residue_idx, chain_encoding_all)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(h_S)\n\u001b[1;32m    173\u001b[0m h_ES \u001b[38;5;241m=\u001b[39m cat_neighbors_nodes(h_S, h_E, E_idx)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Build encoder embeddings\u001b[39;00m\n\u001b[1;32m    178\u001b[0m h_EX_encoder \u001b[38;5;241m=\u001b[39m cat_neighbors_nodes(torch\u001b[38;5;241m.\u001b[39mzeros_like(h_S), h_E, E_idx)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(loader_train):\n",
    "    print(\"Protein Lengths:\")\n",
    "    print([len(p['seq']) for p in batch], '\\n')\n",
    "    \n",
    "    # chain_M is the mask corresponding to \n",
    "    X, S, mask, lengths, chain_M, residue_idx, mask_self, chain_encoding_all = featurize(batch, torch.device('cpu'))\n",
    "    \n",
    "    # Multiplies the masks element-wise for a logical AND of the two masks, this is also performed in the forward pass.\n",
    "    # This has the effect of selecting only visible chains and only the residues that actually exist (not the padded residues added during batching).\n",
    "    mask_for_loss = mask * chain_M\n",
    "    \n",
    "    # Forward pass (is sequence aware!!), this is what we want to replicate for our model.\n",
    "    log_probs = model(X, S, mask, chain_M, residue_idx, chain_encoding_all)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83499fd5-fca4-4ca4-a246-fb9142401339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31896819-07f6-4b91-95cd-2599a3da69d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
